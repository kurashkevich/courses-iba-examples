<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Short Apache Camel K video</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/5GzzyRwhPAM/quick-apache-camel-k-video.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="camelk" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><category term="Knative" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="video" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-short_apache_camel_k_video</id><updated>2019-04-11T10:27:24Z</updated><published>2019-04-11T10:26:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;You may have seen the work we are doing in the Apache Camel community around &lt;a href="https://github.com/apache/camel-k"&gt;Camel K&lt;/a&gt;.&lt;br /&gt;&lt;a href="https://www.nicolaferraro.me/2018/10/15/introducing-camel-k/"&gt;Nicola introduced Camel K&lt;/a&gt; on his blog a half year ago, with the words&lt;br /&gt;&lt;blockquote class="tr_bq"&gt;Just few months ago, we were discussing about a new project that we could start as part of Apache Camel. A project with the potential to change the way people deal with integration. That project is now here and it’s called “Apache Camel K”.&lt;/blockquote&gt;The Apache Camel K is in active development and its progressing nicely. Yesterday I gave a talk at the KMD Steam conference in Copenhagen, Denmark about &lt;a href="https://www.slideshare.net/davsclaus/serverless-integration-with-knative-and-apache-camel-on-kubernetes"&gt;Serverless Integration with Knative and Camel K on Kubernetes&lt;/a&gt;. As the talk was only 30 minutes I decided not to do any live demos and quickly recorded a 45 second short video of a quick Camel K demo.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;iframe allowfullscreen="" class="YOUTUBE-iframe-video" data-thumbnail-src="https://i.ytimg.com/vi/DQK83Cq--W0/0.jpg" frameborder="0" height="266" src="https://www.youtube.com/embed/DQK83Cq--W0?feature=player_embedded" width="320"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;In the top left corner you have a Camel route in a single Sample.java source file. On the top right corner we have an openshift web console, as I am running a local minishift cluster (Camel K also runs nicely on vanilla Kubernetes, but their web console is not as great as the one from openshift).&lt;br /&gt;In the bottom we have the terminal where I run the Camel K integration with the Camel K CLI tool and the output of the integration is logged in the console. Notice how quickly the rolling upgrade is when I edit and save the Java source code.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=vSuP18V45Bc:qaN31t_bxAA:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=vSuP18V45Bc:qaN31t_bxAA:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=vSuP18V45Bc:qaN31t_bxAA:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=vSuP18V45Bc:qaN31t_bxAA:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=vSuP18V45Bc:qaN31t_bxAA:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=vSuP18V45Bc:qaN31t_bxAA:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=vSuP18V45Bc:qaN31t_bxAA:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/vSuP18V45Bc" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/5GzzyRwhPAM" height="1" width="1" alt=""/&gt;</content><summary>You may have seen the work we are doing in the Apache Camel community around Camel K. Nicola introduced Camel K on his blog a half year ago, with the words Just few months ago, we were discussing about a new project that we could start as part of Apache Camel. A project with the potential to change the way people deal with integration. That project is now here and it’s called “Apache Camel K”.The ...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2019-04-11T10:26:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/vSuP18V45Bc/quick-apache-camel-k-video.html</feedburner:origLink></entry><entry><title>Report from the February 2019 ISO C++ meeting (Core Language working group)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/B5NlAvE2wug/" /><category term="C++" scheme="searchisko:content:tags" /><category term="community" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Programming Languages" scheme="searchisko:content:tags" /><author><name>Jason Merrill</name></author><id>searchisko:content:id:jbossorg_blog-report_from_the_february_2019_iso_c_meeting_core_language_working_group</id><updated>2019-04-11T07:00:12Z</updated><published>2019-04-11T07:00:12Z</published><content type="html">&lt;p&gt;The February 2019 &lt;a href="https://isocpp.org/std/meetings-and-participation/upcoming-meetings"&gt;ISO C++ meeting&lt;/a&gt; was held in Kailua-Kona, Hawaii. As usual, Red Hat sent three developers to the meeting: I attended in the Core Language &lt;a href="https://isocpp.org/std/the-committee"&gt;working group&lt;/a&gt;, Jonathan Wakely in Library, and Thomas Rodgers in SG1 (parallelism and concurrency). The meeting went smoothly, although there was significant uncertainty at the beginning where we would end up. In the end, Modules and Coroutines were accepted into the C++20 draft, so now we have our work cut out for us nailing down the remaining loose corners. Here ar highlights from the meeting.&lt;/p&gt; &lt;p&gt;&lt;span id="more-582757"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h3&gt;&lt;a href="https://wg21.link/P1103R3"&gt;Modules&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Work on Modules is very much continuing at this point. All of the Evolution group&amp;#8217;s Tuesday discussions, and some later in the week, were on various subtleties of Modules, particularly around argument-dependent lookup.  A Monday evening discussion also covered the tooling challenges. I haven&amp;#8217;t been following the design discussions very closely, as Nathan Sidwell is in charge of Modules in GCC, but it seems like we&amp;#8217;re converging on a solid design, with various proofs of concept to address concerns. The global module fragment still makes me nervous, but now that we have header units as well, I&amp;#8217;m satisfied that it won&amp;#8217;t be a huge problem.&lt;/p&gt; &lt;h3&gt;&lt;a href="https://wg21.link/P0912R5"&gt;Coroutines&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Coroutines took up all of Wednesday in Evolution. In addition to the Coroutines TS and Core Coroutines proposals that have been under discussion at past meetings, a third design was presented, referred to as &amp;#8220;Symmetric Coroutines.&amp;#8221; There was a lot of comparison of the different approaches—comparing the different choices made by the different proposals and considering possibilities for future convergence between them. In the end, Evolution voted strongly to go ahead with the design in the Coroutines TS.&lt;/p&gt; &lt;h3&gt;&lt;a href="https://wg21.link/p0542r5"&gt;Contracts&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Contracts was voted into C++20 at an earlier meeting, but the topic still took up all of Monday. There were two competing proposals to address some people&amp;#8217;s nervousness about &amp;#8220;assuming&amp;#8221; a contract condition such that it affects optimization of paths of execution that include the contract.&lt;/p&gt; &lt;p&gt;It has always seemed to me that if you have contracts that can continue, those conditions must not be assumed by subsequent code. But, if a contract check cannot continue, naturally the check can be assumed by subsequent code, because if it had been false execution would not have continued. So, the question of whether a condition can be assumed reduces to whether or not the check can continue. The two proposals both wanted to increase explicit control over this, one by adding the &amp;#8220;continue&amp;#8221; keyword to the constructor, and the other by introducing explicit semantics like check_maybe_continue to be used instead of contract levels like &amp;#8220;default.&amp;#8221; I&amp;#8217;m sure we&amp;#8217;ll see more about this at the next meeting.&lt;/p&gt; &lt;p&gt;There has also been nervousness about backward propagation of assumed conditions based on the existing wording that an unchecked contract that would have failed is undefined behavior; compilers optimize based on the assumption that undefined behavior can&amp;#8217;t happen, and mark code as unreachable accordingly. I think this worry is exaggerated, because back-propagation of undefined conditions happens in most optimizers already (e.g., with null pointer dereference) and this would just make the conditions clearer. Checked contracts wouldn&amp;#8217;t back-propagate, as the contract handler might not return.&lt;/p&gt; &lt;p&gt;One proposal was made to change &amp;#8220;expects&amp;#8221;/&amp;#8221;ensures&amp;#8221; to &amp;#8220;pre&amp;#8221;/&amp;#8221;post&amp;#8221;; this suggestion was well received and will probably go in at the next meeting.&lt;/p&gt; &lt;h3&gt;Reflection&lt;/h3&gt; &lt;p&gt;Core spent a while on &lt;a href="http://wg21.link/P1390R1"&gt;responses to national body comments&lt;/a&gt; on the &lt;a href="http://wg21.link/N4766"&gt;Reflection TS&lt;/a&gt;, and the TS as changed was approved for publication. It&amp;#8217;s unclear whether this approach to reflection (using magic types) will end up being the one that goes into the standard, but we think it&amp;#8217;s well specified at this point.&lt;/p&gt; &lt;p&gt;Here are some of the smaller papers that went in:&lt;/p&gt; &lt;p&gt;Extending structured bindings (&lt;a href="https://wg21.link/p1091r3"&gt;P1091R3&lt;/a&gt;, &lt;a href="https://wg21.link/p1381r1"&gt;P1381R1&lt;/a&gt;), which allows structured bindings to be declared static and thread_local and to be captured by lambdas.&lt;/p&gt; &lt;p&gt;&lt;a href="https://wg21.link/P0960R3"&gt;Allow initializing aggregates from a parenthesized list of values&lt;/a&gt;, so now all aggregate classes can be initialized using the normal syntax for calling a constructor, with similar semantics. For example, in a constructor call, a temporary bound to a reference member is not extended, and braces are not elided. This was requested to support usage by library object factory functions like make_unique.&lt;/p&gt; &lt;p&gt;&lt;a href="https://wg21.link/P1009R2"&gt;Array size deduction in new-expressions&lt;/a&gt;, allowing &lt;code&gt;new T[]{ ... }&lt;/code&gt; to deduce the size of the allocated array from the initializer, like we do already for variables.&lt;/p&gt; &lt;p&gt;&lt;a href="https://wg21.link/P1185R2"&gt;&amp;#60;=&amp;#62; != ==&lt;/a&gt;, which changes defaulted operator== to use member == rather than &amp;#60;=&amp;#62; for reasons of efficiency.&lt;/p&gt; &lt;p&gt;Here are some other papers we looked at, which weren&amp;#8217;t quite ready this week:&lt;/p&gt; &lt;p&gt;&lt;a href="http://wg21.link/P1021R3"&gt;Filling Holes in Class Template Argument Deduction&lt;/a&gt;, which proposes to allow CTAD for aggregates, alias templates, and inherited constructors.&lt;/p&gt; &lt;p&gt;&lt;a href="http://wg21.link/P0848R1"&gt;Conditionally Trivial Special Member Functions&lt;/a&gt;, which aims to allow a constructor with certain (Concepts) constraints to be trivial while a constructor with different constraints is not, and have whether the class is trivially copyable depend on which is selected for a particular instantiation of the class.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://isocpp.org/std/meetings-and-participation/upcoming-meetings"&gt;next meeting&lt;/a&gt; will be in July in Cologne, Germany.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F11%2Freport-from-the-february-2019-iso-c-meeting-core-language-working-group%2F&amp;#38;linkname=Report%20from%20the%20February%202019%20ISO%20C%2B%2B%20meeting%20%28Core%20Language%20working%20group%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F11%2Freport-from-the-february-2019-iso-c-meeting-core-language-working-group%2F&amp;#38;linkname=Report%20from%20the%20February%202019%20ISO%20C%2B%2B%20meeting%20%28Core%20Language%20working%20group%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F11%2Freport-from-the-february-2019-iso-c-meeting-core-language-working-group%2F&amp;#38;linkname=Report%20from%20the%20February%202019%20ISO%20C%2B%2B%20meeting%20%28Core%20Language%20working%20group%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F11%2Freport-from-the-february-2019-iso-c-meeting-core-language-working-group%2F&amp;#38;linkname=Report%20from%20the%20February%202019%20ISO%20C%2B%2B%20meeting%20%28Core%20Language%20working%20group%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F11%2Freport-from-the-february-2019-iso-c-meeting-core-language-working-group%2F&amp;#38;linkname=Report%20from%20the%20February%202019%20ISO%20C%2B%2B%20meeting%20%28Core%20Language%20working%20group%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F11%2Freport-from-the-february-2019-iso-c-meeting-core-language-working-group%2F&amp;#38;linkname=Report%20from%20the%20February%202019%20ISO%20C%2B%2B%20meeting%20%28Core%20Language%20working%20group%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F11%2Freport-from-the-february-2019-iso-c-meeting-core-language-working-group%2F&amp;#38;linkname=Report%20from%20the%20February%202019%20ISO%20C%2B%2B%20meeting%20%28Core%20Language%20working%20group%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F11%2Freport-from-the-february-2019-iso-c-meeting-core-language-working-group%2F&amp;#38;linkname=Report%20from%20the%20February%202019%20ISO%20C%2B%2B%20meeting%20%28Core%20Language%20working%20group%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F11%2Freport-from-the-february-2019-iso-c-meeting-core-language-working-group%2F&amp;#038;title=Report%20from%20the%20February%202019%20ISO%20C%2B%2B%20meeting%20%28Core%20Language%20working%20group%29" data-a2a-url="https://developers.redhat.com/blog/2019/04/11/report-from-the-february-2019-iso-c-meeting-core-language-working-group/" data-a2a-title="Report from the February 2019 ISO C++ meeting (Core Language working group)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/11/report-from-the-february-2019-iso-c-meeting-core-language-working-group/"&gt;Report from the February 2019 ISO C++ meeting (Core Language working group)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/B5NlAvE2wug" height="1" width="1" alt=""/&gt;</content><summary>The February 2019 ISO C++ meeting was held in Kailua-Kona, Hawaii. As usual, Red Hat sent three developers to the meeting: I attended in the Core Language working group, Jonathan Wakely in Library, and Thomas Rodgers in SG1 (parallelism and concurrency). The meeting went smoothly, although there was significant uncertainty at the beginning where we would end up. In the end, Modules and Coroutines ...</summary><dc:creator>Jason Merrill</dc:creator><dc:date>2019-04-11T07:00:12Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/11/report-from-the-february-2019-iso-c-meeting-core-language-working-group/</feedburner:origLink></entry><entry><title>Red Hat Summit 2019: Emerging Technology Labs Roadmap</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/vHwefMy3BR8/red-hat-summit-2019-emerging-technology-labs-roadmap.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="Decision Manager" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="JBossAMQ" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-red_hat_summit_2019_emerging_technology_labs_roadmap</id><updated>2019-04-11T05:00:06Z</updated><published>2019-04-11T05:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;a href="https://reg.summit.redhat.com/" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" target="_blank"&gt;&lt;img border="0" data-original-height="389" data-original-width="769" height="161" src="https://1.bp.blogspot.com/-yX0WaXZmaTI/XJj8CSvWUlI/AAAAAAAAth4/4Z1aZQ7VOp061sKNZ-_kMauutZPP46AMgCLcBGAs/s320/Screenshot%2B2019-03-25%2Bat%2B17.04.08.png" width="320" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.redhat.com/en/summit/2019" target="_blank"&gt;Red Hat Summit 2019&lt;/a&gt; is rocking Boston, MA from May 7-9th in the &lt;a href="https://www.signatureboston.com/BCEC" target="_blank"&gt;Boston Convention and Exhibition Center&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Everything you need to know about the current state of open source enterprise ready software can be found at this event. From customers talking about their experiences leveraging open source in their solutions, to the creators of open source technologies you're using, and all the way down to hands-on lab experiences on these technologies.&lt;br /&gt;&lt;br /&gt;This hands-on appeal is what this series of articles is about. It's&amp;nbsp;interesting to take a tour, so starting with this article let's examine a series of instructor-led labs based on a specific theme.&lt;br /&gt;&lt;br /&gt;This week it's a roadmap to&amp;nbsp;&lt;i&gt;emerging technology&amp;nbsp;&lt;/i&gt;lab content.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;The following labs can be found in the &lt;a href="https://summit.redhat.com/conference/sessions" target="_blank"&gt;session catalog online&lt;/a&gt;, by searching on title or filtering on &lt;i&gt;instructor-led labs &lt;/i&gt;and &lt;i&gt;emerging technology.&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Analytics and machine learning with Red Hat infrastructure&lt;/h3&gt;&lt;i&gt;As data is exponentially growing in organizations, there is an increasing need to consolidate silos of information into a single source of truth, or ‘Data Lake’ to feed hungry Analytics and Machine Learning Engines that can gather insight at scale.&lt;br /&gt;&lt;br /&gt;In this session, we'll detail how to architect data infrastructure services using Red Hat OpenShift, Red Hat Ceph Storage, and doing analytics with Spark and TensorFlow. In the hands-on segment of the lab, we'll deploy Open Data Hub and use Jupyter notebooks to walk through interacting with data sets using the S3A filesystem client and using Spark schema detection and SparkSQL to query data. We'll then look at how to use TensorFlow to create a model to classify data, how to integrate TensorFlow models and Spark, and at how to serve that data using Red Hat OpenShift.&lt;br /&gt;&lt;br /&gt;Speakers: Kyle Bader, Sean Pryor, Sherard Griffin&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Machine learning workflows for application developers&lt;/h3&gt;&lt;i&gt;The capabilities of intelligent applications often seem like magic to users, but the machine learning and artificial intelligence techniques that provide these features are more accessible than you might think. Developing intelligent features doesn’t require esoteric math or high-performance hardware, but it does require you to adapt your existing engineering practice to build and manage predictive models in addition to conventional software artifacts.&lt;br /&gt;&lt;br /&gt;This hands-on lab will introduce machine learning workflows and show you how to integrate them into the application development work you’re already doing, focusing on the habits and processes that will help you to get meaningful results from application intelligence. During this lab, Red Hat machine learning experts will help you:&lt;br /&gt;&lt;/i&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;Build intelligent application functionality from the ground up, by training, evaluating, and deploying predictive models.&lt;/i&gt;&lt;/li&gt;&lt;i&gt;&lt;li&gt;Incorporate machine learning into your general software development discipline.&lt;/li&gt;&lt;li&gt;See how to apply techniques like continuous integration, iterative development, and monitoring while building intelligent features for your apps.&lt;/li&gt;&lt;li&gt;Learn how the development platforms you love, like Red Hat Middleware and Red Hat OpenShift Container Platform, support every phase of intelligent application development.&lt;/li&gt;&lt;/i&gt;&lt;/ul&gt;&lt;i&gt; Speakers: Sophie Watson, William Benton, Michael McCune&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Next-gen technologies at scale: Building solutions to manage tomorrow’s workloads&lt;/h3&gt;&lt;i&gt;For emerging technologies like Internet of Things (IoT), virtual reality (VR), and 5G, a large amount of data is generated outside the datacenter—for example, a refinery can generate 1TB data per day. A lot of this data is redundant, yet an event for critical equipment would require a near real-time response. This requires a large amount of data processing at the edge as well as reducing the data volume sent to datacenter or cloud.&lt;br /&gt;&lt;br /&gt;In this lab, you'll learn how to use a combination of Red Hat technologies, such as Red Hat Decision Manager, Red Hat AMQ streams, and Red hat OpenShift Container Platform to build integrated solutions to meet most demanding workloads. In particular, we'll cover using the features of AMQ streams—such as stream processing, metering, and event sourcing—to build solutions that scale for complex environments. Patterns used in this lab are designed to be extensible, so that you'll understand how to implement your own adaptive solutions afterwards.&lt;br /&gt;&lt;br /&gt;Speakers: Hugo Guerrero, Sam Rang, Andrew Block, Christina WeiMei Lin, Ishu Verma&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;Stay tuned for more articles with insights into other themes that might interest you enough to register for one of these instructor-led labs at Red Hat Summit 2019.&lt;br /&gt;&lt;br /&gt;Looking forward to seeing you there!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ekpEuv92s5s:0QowWOhTnA0:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ekpEuv92s5s:0QowWOhTnA0:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ekpEuv92s5s:0QowWOhTnA0:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ekpEuv92s5s:0QowWOhTnA0:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ekpEuv92s5s:0QowWOhTnA0:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ekpEuv92s5s:0QowWOhTnA0:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ekpEuv92s5s:0QowWOhTnA0:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ekpEuv92s5s:0QowWOhTnA0:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ekpEuv92s5s:0QowWOhTnA0:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ekpEuv92s5s:0QowWOhTnA0:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ekpEuv92s5s:0QowWOhTnA0:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/ekpEuv92s5s" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/vHwefMy3BR8" height="1" width="1" alt=""/&gt;</content><summary>Red Hat Summit 2019 is rocking Boston, MA from May 7-9th in the Boston Convention and Exhibition Center. Everything you need to know about the current state of open source enterprise ready software can be found at this event. From customers talking about their experiences leveraging open source in their solutions, to the creators of open source technologies you're using, and all the way down to ha...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-04-11T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/ekpEuv92s5s/red-hat-summit-2019-emerging-technology-labs-roadmap.html</feedburner:origLink></entry><entry><title>Speed up SystemTap scripts with statistical aggregates</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/V__s_JRkjM4/" /><category term="developer" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="performance" scheme="searchisko:content:tags" /><category term="Programming Languages" scheme="searchisko:content:tags" /><category term="tutorial" scheme="searchisko:content:tags" /><author><name>William Cohen</name></author><id>searchisko:content:id:jbossorg_blog-speed_up_systemtap_scripts_with_statistical_aggregates</id><updated>2019-04-10T13:30:46Z</updated><published>2019-04-10T13:30:46Z</published><content type="html">&lt;p&gt;A common question that SystemTap can be used to answer involves how often particular events occur on the system. Some events, such as system calls, can happen frequently and the goal is to make the SystemTap script as efficient as possible.&lt;/p&gt; &lt;p&gt;Using the statistical aggregate in the place of regular integers is one way to improve the performance of SystemTap scripts. The statistical aggregates record data on a per-CPU basis to reduce the amount of coordination required between processors, allowing information to be recorded with less overhead. In this article, I’ll show an example of how to reduce overhead in SystemTap scripts.&lt;span id="more-519607"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Below is a version of the &lt;code&gt;syscalls_by_proc.stp&lt;/code&gt; example script that tallies the number of times each executable makes a system call. When the script exits, it prints out the number of times each executable on the system make a system call sorted from most to fewest system calls.&lt;/p&gt; &lt;p&gt;Line 1 defines the global array used to store the information. Line 3 is the probe that actually tallies each system call using the &lt;code&gt;++&lt;/code&gt;. The probe end starting at line 5 prints out the data stored in the global syscalls associative array.&lt;/p&gt; &lt;pre&gt;global syscalls probe kernel.trace("sys_enter") { syscalls[execname()] ++ } probe end { printf ("%-10s %-s\n", "#SysCalls", "Process Name") foreach (proc in syscalls-) printf("%-10d %-s\n", syscalls[proc], proc) }&lt;/pre&gt; &lt;p&gt;The following code example shows a run of the previous script. The &lt;code&gt;-v&lt;/code&gt; option causes SystemTap to provide timing information for each of the five passes passes. The &lt;code&gt;-t&lt;/code&gt; provides timing information for each of the probes in the script and will provide a way to compare the efficiency of the different implementations. The &lt;code&gt;-c "make -j8"&lt;/code&gt; starts the make command once the SystemTap instrumentation is ready and stops the instrumentation once the command finishes. At the end of the output is the &amp;#8220;probe hit report,&amp;#8221; which provides information about the overhead of the various probes.&lt;/p&gt; &lt;p&gt;The middle of line for the &lt;code&gt;kernel.trace("raw_syscalls:sys_enter")&lt;/code&gt; shows it was triggered more than 24 million times. The middle of that same line states it took an average of 4224 clock cycles to do the operation. Also over 3 million lock contentions occur on the global associative array &lt;code&gt;(__global_syscall)&lt;/code&gt; in the &amp;#8220;refresh report&amp;#8221; section.&lt;/p&gt; &lt;pre&gt;$ stap -v -t ~/present/2019blog/fast/syscalls_by_proc.stp -c "make -j8" Pass 1: parsed user script and 504 library scripts using 290680virt/85620res/3552shr/82780data kb, in 590usr/30sys/621real ms. Pass 2: analyzed script: 2 probes, 1 function, 0 embeds, 1 global using 296352virt/92244res/4484shr/88452data kb, in 130usr/190sys/331real ms. Pass 3: using cached /home/wcohen/.systemtap/cache/b8/stap_b8412b9e49934149b789a69c3e2a2b4e_1469.c Pass 4: using cached /home/wcohen/.systemtap/cache/b8/stap_b8412b9e49934149b789a69c3e2a2b4e_1469.ko Pass 5: starting run. DESCEND objtool CALL scripts/atomic/check-atomics.sh CALL scripts/checksyscalls.sh CHK include/generated/compile.h TEST posttest Building modules, stage 2. MODPOST 3484 modules arch/x86/tools/insn_decoder_test: success: Decoded and checked 5057175 instructions TEST posttest arch/x86/tools/insn_sanity: Success: decoded and checked 1000000 random instructions with 0 errors (seed:0x18e55059) Kernel: arch/x86/boot/bzImage is ready (#9) #SysCalls Process Name 22614118 make 1675055 sh 138647 awk 112797 modpost 93456 cat 69563 objdump 68771 insn_decoder_te 49887 grep 14656 cc1 13544 gcc 11714 rm 10174 as ... ----- probe hit report: kernel.trace("raw_syscalls:sys_enter"), (/home/wcohen/present/2019blog/fast/syscalls_by_proc.stp:17:1), hits: 24894191, cycles: 310min/4224avg/477851max, variance: 5282267, from: kernel.trace("sys_enter"), index: 0 end, (/home/wcohen/present/2019blog/fast/syscalls_by_proc.stp:21:1), hits: 1, cycles: 109027min/109027avg/109027max, variance: 0, from: end, index: 1 ----- refresh report: '__global_syscalls' lock contention occurred 3230491 times Pass 5: run completed in 174200usr/100470sys/69766real ms. &lt;/pre&gt; &lt;p&gt;The overhead of the script can be significantly reduce by using statistical aggregates. The &lt;code&gt;++&lt;/code&gt; is replaced by a &lt;code&gt;&amp;#60;&amp;#60;&amp;#60; 1&lt;/code&gt; to tally each system call and the tallies are now printed with a &lt;code&gt;@sum(syscalls[proc])&lt;/code&gt; in the code below.&lt;/p&gt; &lt;pre&gt;global syscalls probe kernel.trace("sys_enter") { syscalls[execname()] &amp;#38;lt;&amp;#38;lt;&amp;#38;lt; 1 } probe end { printf ("%-10s %-s\n", "#SysCalls", "Process Name") foreach (proc in syscalls-) printf("%-10d %-s\n", @sum(syscalls[proc]), proc) } &lt;/pre&gt; &lt;p&gt;Below is an equivalent run of the script using the statistical aggregates in place of the slower &lt;code&gt;++&lt;/code&gt;. Looking at the &amp;#8220;probe hit report&amp;#8221; toward the end of the listing, you will see there the &lt;code&gt;raw_syscalls:sys_enter&lt;/code&gt; trace point was run a similar number of times as the other script, about 25 million times. However, notice that the average time required by the handler is 409 clock cycles, much lower that the 4224 cycles observed on the version with &lt;code&gt;++&lt;/code&gt;. There is no lock contention listed for the syscalls associative array listed in the &amp;#8220;refresh report&amp;#8221; section for the run using statistical aggregates either.&lt;/p&gt; &lt;pre&gt;$ stap -v -t ~/present/2019blog/faster/syscalls_by_proc.stp -c "make -j8" Pass 1: parsed user script and 504 library scripts using 290680virt/85624res/3552shr/82780data kb, in 580usr/30sys/616real ms. Pass 2: analyzed script: 2 probes, 1 function, 0 embeds, 1 global using 296348virt/92256res/4492shr/88448data kb, in 140usr/190sys/332real ms. Pass 3: using cached /home/wcohen/.systemtap/cache/de/stap_de5d5dc935de72aac43603205a17cad4_1482.c Pass 4: using cached /home/wcohen/.systemtap/cache/de/stap_de5d5dc935de72aac43603205a17cad4_1482.ko Pass 5: starting run. DESCEND objtool CALL scripts/atomic/check-atomics.sh CALL scripts/checksyscalls.sh CHK include/generated/compile.h TEST posttest Building modules, stage 2. MODPOST 3484 modules arch/x86/tools/insn_decoder_test: success: Decoded and checked 5057175 instructions TEST posttest arch/x86/tools/insn_sanity: Success: decoded and checked 1000000 random instructions with 0 errors (seed:0xbefec711) Kernel: arch/x86/boot/bzImage is ready (#9) #SysCalls Process Name 22616433 make 1675055 sh 138647 awk 112797 modpost 93456 cat 69563 objdump 68771 insn_decoder_te 49891 grep 14706 cc1 13544 gcc 11714 rm 10174 as ... ----- probe hit report: kernel.trace("raw_syscalls:sys_enter"), (/home/wcohen/present/2019blog/faster/syscalls_by_proc.stp:17:1), hits: 24895995, cycles: 216min/409avg/395696max, variance: 3425671, from: kernel.trace("sys_enter"), index: 0 end, (/home/wcohen/present/2019blog/faster/syscalls_by_proc.stp:19:1), hits: 1, cycles: 847759min/847759avg/847759max, variance: 0, from: end, index: 1 ----- refresh report: Pass 5: run completed in 172780usr/66010sys/64215real ms. &lt;/pre&gt; &lt;p&gt;The tradeoff of using the statistical aggregates is that when using the &lt;code&gt;@sum()&lt;/code&gt; is that the data needs to be fetched from all the processors in the machine. This is more expensive than just fetching a single integer value stored in an associative array. However, for this example, reducing the overhead of the system call probes more than makes up for the overhead of &lt;code&gt;@sum()&lt;/code&gt; used to print the results.&lt;/p&gt; &lt;p&gt;When writing SystemTap scripts, you can use the &lt;code&gt;-t&lt;/code&gt; option to better understand the overhead of your scripts and consider using the statistical aggregates when feasible. As this example shows, the overhead in instrumentation scripts can be significantly reduced in SystemTap scripts.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Fspeed-up-systemtap-scripts-with-statistical-aggregates%2F&amp;#38;linkname=Speed%20up%20SystemTap%20scripts%20with%20statistical%20aggregates" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Fspeed-up-systemtap-scripts-with-statistical-aggregates%2F&amp;#38;linkname=Speed%20up%20SystemTap%20scripts%20with%20statistical%20aggregates" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Fspeed-up-systemtap-scripts-with-statistical-aggregates%2F&amp;#38;linkname=Speed%20up%20SystemTap%20scripts%20with%20statistical%20aggregates" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Fspeed-up-systemtap-scripts-with-statistical-aggregates%2F&amp;#38;linkname=Speed%20up%20SystemTap%20scripts%20with%20statistical%20aggregates" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Fspeed-up-systemtap-scripts-with-statistical-aggregates%2F&amp;#38;linkname=Speed%20up%20SystemTap%20scripts%20with%20statistical%20aggregates" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Fspeed-up-systemtap-scripts-with-statistical-aggregates%2F&amp;#38;linkname=Speed%20up%20SystemTap%20scripts%20with%20statistical%20aggregates" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Fspeed-up-systemtap-scripts-with-statistical-aggregates%2F&amp;#38;linkname=Speed%20up%20SystemTap%20scripts%20with%20statistical%20aggregates" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Fspeed-up-systemtap-scripts-with-statistical-aggregates%2F&amp;#38;linkname=Speed%20up%20SystemTap%20scripts%20with%20statistical%20aggregates" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Fspeed-up-systemtap-scripts-with-statistical-aggregates%2F&amp;#038;title=Speed%20up%20SystemTap%20scripts%20with%20statistical%20aggregates" data-a2a-url="https://developers.redhat.com/blog/2019/04/10/speed-up-systemtap-scripts-with-statistical-aggregates/" data-a2a-title="Speed up SystemTap scripts with statistical aggregates"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/10/speed-up-systemtap-scripts-with-statistical-aggregates/"&gt;Speed up SystemTap scripts with statistical aggregates&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/V__s_JRkjM4" height="1" width="1" alt=""/&gt;</content><summary>A common question that SystemTap can be used to answer involves how often particular events occur on the system. Some events, such as system calls, can happen frequently and the goal is to make the SystemTap script as efficient as possible. Using the statistical aggregate in the place of regular integers is one way to improve the performance of SystemTap scripts. The statistical aggregates record ...</summary><dc:creator>William Cohen</dc:creator><dc:date>2019-04-10T13:30:46Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/10/speed-up-systemtap-scripts-with-statistical-aggregates/</feedburner:origLink></entry><entry><title>Eclipse Wild Web Developer adds a powerful YAML editor with built-in Kubernetes support</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/uZ86P9aeE2g/" /><category term="Announcement" scheme="searchisko:content:tags" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="Eclipse" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><author><name>Xi Yan</name></author><id>searchisko:content:id:jbossorg_blog-eclipse_wild_web_developer_adds_a_powerful_yaml_editor_with_built_in_kubernetes_support</id><updated>2019-04-10T07:03:02Z</updated><published>2019-04-10T07:03:02Z</published><content type="html">&lt;p&gt;YAML Ain&amp;#8217;t Markup Language (YAML) has grown increasingly popular during the past few years. It is a human-readable text-based format for specifying configuration information and is used in many platforms, such as &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://www.openshift.com/"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a href="https://marketplace.eclipse.org/content/eclipse-wild-web-developer-web-development-eclipse-ide"&gt;Eclipse Wild Web Developer&lt;/a&gt; is a language-based extension that provides a rich development experience for developing typical web and configuration files in the Eclipse IDE. According to the &lt;a href="https://projects.eclipse.org/proposals/eclipse-wild-web-developer"&gt;project page&lt;/a&gt;, &amp;#8220;Eclipse Wild Web Developer relies on existing mainstream and maintained components to provide the language smartness, over popular configuration files like TextMate and protocols like &lt;a href="https://microsoft.github.io/language-server-protocol/"&gt;Language Server Protocol &lt;/a&gt; or Debug Adapter Protocol.&amp;#8221;&lt;/p&gt; &lt;p&gt;Recently, the &lt;a href="https://github.com/redhat-developer/yaml-language-server"&gt;YAML Language Server&lt;/a&gt; has been integrated into Eclipse Wild Web Developer. This is a feature-rich YAML Language Server implementation that also powers editors including VSCode, Eclipse Che, and Atom. This integration brings all the features that Language Server supports, including validation, autocompletion, hover support, and document outlining to the Eclipse Generic Editor, making it much easier to write and maintain YAML files.&lt;span id="more-580147"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;To get these features, you can download the &lt;a href="https://marketplace.eclipse.org/content/eclipse-wild-web-developer-web-development-eclipse-ide"&gt;Wild Web Developer&lt;/a&gt; in the Eclipse Marketplace.&lt;/p&gt; &lt;h3&gt;Demo&lt;/h3&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/P9ETtuHiUco?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h3&gt;General YAML support&lt;/h3&gt; &lt;p&gt;If you open any &lt;code&gt;.yaml&lt;/code&gt; or &lt;code&gt;.yml&lt;/code&gt; file with the Eclipse Generic Editor with Wild Web Developer installed, you&amp;#8217;ll find it has all the features you&amp;#8217;d expect to find in a language based editor, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Syntax highlighting&lt;/li&gt; &lt;li&gt;YAML validation&lt;/li&gt; &lt;li&gt;Document outlining&lt;/li&gt; &lt;li&gt;Formatting&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Built-in Kubernetes and custom schemas support&lt;/h3&gt; &lt;p&gt;In addition to general YAML support, Wild Web Developer provides built-in Kubernetes syntax support, as well as support for validation for custom schemas through the YAML Language Server.&lt;/p&gt; &lt;p&gt;Out of the box, the YAML Language server will automatically check SchemaStore to provide syntax, structure, and value validation based on a matching schema. You may also manually associate schemas to your YAML files by going to &lt;em&gt;Preferences -&amp;#62; YAML -&amp;#62; YAML Schemas&lt;/em&gt; and adding the corresponding schemas.&lt;/p&gt; &lt;p&gt;In the &lt;em&gt;Schema&lt;/em&gt; section, you may specify built-in Kubernetes definitions, such as &amp;#8220;kubernetes&amp;#8221; or &amp;#8220;kedge,&amp;#8221; or any URLs pointing to a valid schema. The &lt;em&gt;Glob Pattern&lt;/em&gt; parameter is used to match the schemas to a file path. For example, you can specify it as /* to apply the schema to all YAML files in the project, or use the flexibility to specify different schemas for different files or directories.&lt;/p&gt; &lt;p&gt;Once this is done, you can access all the schema-related features like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Autocompletion: autocompletes properties or node values to schema&amp;#8217;s default&lt;/li&gt; &lt;li&gt;Hovers: hovering over a property shows a description&lt;/li&gt; &lt;li&gt;Schema validation: validating structure and values of your file against the schema&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Contributing&lt;/h3&gt; &lt;p&gt;If you are a developer working with YAML files or any typical web languages, then check out Wild Web Developer and see how it compares to your current workflow. If you would like to contribute, feel free to submit any issues, pull requests, or comments at: &lt;a href="https://github.com/eclipse/wildwebdeveloper"&gt;https://github.com/eclipse/wildwebdeveloper&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Feclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support%2F&amp;#38;linkname=Eclipse%20Wild%20Web%20Developer%20adds%20a%20powerful%20YAML%20editor%20with%20built-in%20Kubernetes%20support" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Feclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support%2F&amp;#38;linkname=Eclipse%20Wild%20Web%20Developer%20adds%20a%20powerful%20YAML%20editor%20with%20built-in%20Kubernetes%20support" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Feclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support%2F&amp;#38;linkname=Eclipse%20Wild%20Web%20Developer%20adds%20a%20powerful%20YAML%20editor%20with%20built-in%20Kubernetes%20support" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Feclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support%2F&amp;#38;linkname=Eclipse%20Wild%20Web%20Developer%20adds%20a%20powerful%20YAML%20editor%20with%20built-in%20Kubernetes%20support" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Feclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support%2F&amp;#38;linkname=Eclipse%20Wild%20Web%20Developer%20adds%20a%20powerful%20YAML%20editor%20with%20built-in%20Kubernetes%20support" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Feclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support%2F&amp;#38;linkname=Eclipse%20Wild%20Web%20Developer%20adds%20a%20powerful%20YAML%20editor%20with%20built-in%20Kubernetes%20support" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Feclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support%2F&amp;#38;linkname=Eclipse%20Wild%20Web%20Developer%20adds%20a%20powerful%20YAML%20editor%20with%20built-in%20Kubernetes%20support" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Feclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support%2F&amp;#38;linkname=Eclipse%20Wild%20Web%20Developer%20adds%20a%20powerful%20YAML%20editor%20with%20built-in%20Kubernetes%20support" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F10%2Feclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support%2F&amp;#038;title=Eclipse%20Wild%20Web%20Developer%20adds%20a%20powerful%20YAML%20editor%20with%20built-in%20Kubernetes%20support" data-a2a-url="https://developers.redhat.com/blog/2019/04/10/eclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support/" data-a2a-title="Eclipse Wild Web Developer adds a powerful YAML editor with built-in Kubernetes support"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/10/eclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support/"&gt;Eclipse Wild Web Developer adds a powerful YAML editor with built-in Kubernetes support&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/uZ86P9aeE2g" height="1" width="1" alt=""/&gt;</content><summary>YAML Ain’t Markup Language (YAML) has grown increasingly popular during the past few years. It is a human-readable text-based format for specifying configuration information and is used in many platforms, such as Kubernetes and Red Hat OpenShift. Eclipse Wild Web Developer is a language-based extension that provides a rich development experience for developing typical web and configuration files i...</summary><dc:creator>Xi Yan</dc:creator><dc:date>2019-04-10T07:03:02Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/10/eclipse-wild-web-developer-adds-a-powerful-yaml-editor-with-built-in-kubernetes-support/</feedburner:origLink></entry><entry><title>From zero to Quarkus and Knative: The easy way</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1fedqc_MGws/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="Knative" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="minishift" scheme="searchisko:content:tags" /><category term="OpenShift Enterprise by Red Hat" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><category term="serverless" scheme="searchisko:content:tags" /><author><name>Alessandro Arrichiello</name></author><id>searchisko:content:id:jbossorg_blog-from_zero_to_quarkus_and_knative_the_easy_way</id><updated>2019-04-09T07:03:44Z</updated><published>2019-04-09T07:03:44Z</published><content type="html">&lt;p&gt;You&amp;#8217;ve probably already read about &lt;a href="https://developers.redhat.com/blog/2019/03/07/quarkus-next-generation-kubernetes-native-java-framework/"&gt;Quarkus&lt;/a&gt;, but you may not know that the superfast startup speed of Quarkus makes it the best candidate for working with Knative and serverless for your Function-as-a-Service (FaaS) projects.&lt;/p&gt; &lt;p&gt;Quarkus, also known as Supersonic, Subatomic Java, is a Kubernetes native Java stack tailored for GraalVM and OpenJDK HotSpot, crafted from the best-of-breed Java libraries and standards. &lt;a href="https://developers.redhat.com/blog/2019/03/20/knative-what-developers-need-to-know/"&gt;Knative&lt;/a&gt; is a Kubernetes-based platform to build, deploy, and manage modern serverless workloads. You can learn more in this &lt;a href="https://blog.openshift.com/knative-serving-your-serverless-services/"&gt;article series&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article does not provide a full deep dive on Knative or Quarkus. Instead, I aim to give you a quick and easy way to start playing with both technologies so you can further explore on your own.&lt;span id="more-581277"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;In the following examples, I assume you&amp;#8217;ve already installed a Minishift machine. &lt;a href="https://www.okd.io/minishift/"&gt;Minishift&lt;/a&gt; is a tool that helps you run &lt;a href="https://www.okd.io/"&gt;OKD&lt;/a&gt; locally by launching a single-node OKD cluster inside a virtual machine. With Minishift, you can try out OKD or develop with it, day-to-day, on your local machine (Linux, Windows, or Mac).&lt;/p&gt; &lt;p&gt;Please keep in mind that, in this example, I&amp;#8217;m using the upstream version of Minishift; of course, you can replicate and run all the stuff on the &lt;a href="https://developers.redhat.com/products/cdk/overview/"&gt;Container Development Kit (CDK)&lt;/a&gt; by Red Hat.&lt;/p&gt; &lt;p&gt;I&amp;#8217;ll execute all the following commands as a cluster administrator in the Red Hat OpenShift environment. Thus, you should switch to an admin user before continuing.&lt;/p&gt; &lt;h2&gt;Warm up the engines&lt;/h2&gt; &lt;p&gt;To begin, we need to set up Knative on Minishift. To do this, we need to clone the Minishift add-ons for Knative by the OpenShift team:&lt;/p&gt; &lt;pre&gt;$ git clone https://github.com/openshift-cloud-functions/minishift-addons $ minishift addons install minishift-addons/knative-istio $ minishift addons install minishift-addons/knative-build $ minishift addons install minishift-addons/knative-serving $ minishift addons install minishift-addons/knative-eventing&lt;/pre&gt; &lt;p&gt;After that, we can start the installation process for the first add-on: knative-istio.&lt;/p&gt; &lt;pre&gt;$ minishift addons apply knative-istio&lt;/pre&gt; &lt;p&gt;Once that step is complete, you can install the Knative resources:&lt;/p&gt; &lt;pre&gt;$ minishift addons apply knative-build $ minishift addons apply knative-serving $ minishift addons apply knative-eventing&lt;/pre&gt; &lt;p&gt;When you&amp;#8217;ve finished with all this setup, you should find a bunch of new pods running for enabling your Minishift to Knative:&lt;/p&gt; &lt;pre&gt;$ oc get pods --all-namespaces ... knative-build build-controller-85b9c8d7f-f6jj4 1/1 Running 0 2m knative-build build-webhook-66bfc7ffc8-8s9tq 1/1 Running 0 2m knative-eventing controller-manager-0 1/1 Running 0 1m knative-eventing eventing-controller-7d69f6945b-mhrrj 1/1 Running 0 1m knative-eventing in-memory-channel-controller-569f959967-qkt96 1/1 Running 0 1m knative-eventing in-memory-channel-dispatcher-c54844b75-5l7bv 1/1 Running 0 1m knative-eventing webhook-667567bc86-fz4p7 1/1 Running 0 1m knative-serving activator-5c8d4bbc9d-4mt6l 1/1 Running 0 1m knative-serving activator-5c8d4bbc9d-qw4jh 1/1 Running 0 1m knative-serving activator-5c8d4bbc9d-z65gt 1/1 Running 0 1m knative-serving autoscaler-5d6dcf98f8-pcmqb 1/1 Running 0 1m knative-serving controller-98c69fcc-xjwls 1/1 Running 0 1m knative-serving webhook-68dc778cb5-xmgwm 1/1 Running 0 1m&lt;/pre&gt; &lt;h2&gt;Setting up a Containers Image Registry&lt;/h2&gt; &lt;p&gt;Before playing with Knative Build, we should set up another prerequisite for this quickstart: a container image registry for our Quarkus Knative Build.&lt;/p&gt; &lt;p&gt;Unfortunately, as we&amp;#8217;ll see in few moments, the Quarkus quickstart example will generate (through Maven) Knative Build resources&amp;#8217; files using Kaniko as the Knative Build template. I&amp;#8217;ve tried to make Kaniko work with OpenShift internal registry but I had no luck with that. I also &lt;a href="https://github.com/GoogleContainerTools/kaniko/issues/623"&gt;opened an issue on GitHub&lt;/a&gt; for reporting the behavior.&lt;/p&gt; &lt;p&gt;Unfortunately, &lt;a href="https://github.com/GoogleContainerTools/kaniko/issues/400"&gt;Kaniko doesn&amp;#8217;t seem to play well&lt;/a&gt; with Quay.io Registry either. Another approach could be to move the Knative Build Template from Kaniko to &lt;a href="https://www.projectatomic.io/blog/2017/11/getting-started-with-buildah/"&gt;Buildah&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;But, we want the easiest and fastest way for getting Knative and Quarkus up &amp;#38; running, for this reason, we&amp;#8217;ll use the Dockerhub online registry instead.&lt;/p&gt; &lt;p&gt;To start, log in or register to Dockerhub, and then you&amp;#8217;re ready to create your container repository, named &lt;em&gt;quarkus-greetings.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-581517 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/03/FireShot-Capture-074-Docker-Hub-cloud.docker.com_-1024x506.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/03/FireShot-Capture-074-Docker-Hub-cloud.docker.com_.png" alt="" width="1920" height="949" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/03/FireShot-Capture-074-Docker-Hub-cloud.docker.com_.png 1920w, https://developers.redhat.com/blog/wp-content/uploads/2019/03/FireShot-Capture-074-Docker-Hub-cloud.docker.com_-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/03/FireShot-Capture-074-Docker-Hub-cloud.docker.com_-768x380.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/03/FireShot-Capture-074-Docker-Hub-cloud.docker.com_-1024x506.png 1024w" sizes="(max-width: 1920px) 100vw, 1920px" /&gt;&lt;/p&gt; &lt;p&gt;We can now move forward with the Knative Build.&lt;/p&gt; &lt;h2&gt;Quarkus Knative Build&lt;/h2&gt; &lt;p&gt;We&amp;#8217;re now ready to check out the Quarkus quickstarts repo and start playing with Knative Build.&lt;/p&gt; &lt;pre&gt;$ git clone https://github.com/quarkusio/quarkus-quickstarts $ cd quarkus-quickstarts/getting-started-knative&lt;/pre&gt; &lt;p&gt;Then we can execute the Maven command for building up the Kubernetes resources&amp;#8217; files. We&amp;#8217;ll pass the following parameters to the Maven command:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Container registry URL&lt;/li&gt; &lt;li&gt;Container registry credentials&lt;/li&gt; &lt;li&gt;Git source repo&lt;/li&gt; &lt;li&gt;Target container image to push the build result&lt;/li&gt; &lt;/ul&gt; &lt;pre&gt;$ mvn -Dcontainer.registry.url='https://index.docker.io/v1/' \ &amp;#62; -Dcontainer.registry.user='alezzandro' \ &amp;#62; -Dcontainer.registry.password='XXXXXXXYYYYYYYZZZZZZZZ' \ &amp;#62; -Dgit.source.revision='master' \ &amp;#62; -Dgit.source.repo.url='https://github.com/quarkusio/quarkus-quickstarts.git' \ &amp;#62; -Dapp.container.image='quay.io/alezzandro/quarkus-greetings' \ &amp;#62; clean process-resources [INFO] Scanning for projects... [INFO] [INFO] ----------------&amp;#60; org.acme:quarkus-quickstart-knative &amp;#62;----------------- [INFO] Building quarkus-quickstart-knative 1.0-SNAPSHOT [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ quarkus-quickstart-knative --- [INFO] Deleting /home/alex/gitprojects/quarkus-quickstarts/getting-started-knative/target [INFO] [INFO] --- build-helper-maven-plugin:3.0.0:add-resource (add-resource) @ quarkus-quickstart-knative --- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ quarkus-quickstart-knative --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /home/alex/gitprojects/quarkus-quickstarts/getting-started-knative/src/main/resources [INFO] Copying 6 resources to /home/alex/gitprojects/quarkus-quickstarts/getting-started-knative/target/knative [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 1.840 s [INFO] Finished at: 2019-03-29T13:29:55+01:00 [INFO] ------------------------------------------------------------------------&lt;/pre&gt; &lt;p&gt;The command creates the resource files in &lt;code&gt;target/knative&lt;/code&gt; directory:&lt;/p&gt; &lt;pre&gt;$ ls target/knative/ build-sa.yaml container-registry-secrets.yaml deploy-key.yaml kaniko-pvc.yaml m2-pvc.yaml service.yaml&lt;/pre&gt; &lt;p&gt;By the way, the Maven command can also take as an input Git credentials for pulling down a private Git repo. In any case, we just used the public Quarkus quickstart repo, so we don&amp;#8217;t need the generated &lt;code&gt;deploy-key.yaml&lt;/code&gt; file and its reference in the ServiceAccount contained in &lt;code&gt;build-sa.yaml&lt;/code&gt;. We need to remove them:&lt;/p&gt; &lt;pre&gt;$ rm target/knative/deploy-key.yaml $ cat target/knative/build-sa.yaml apiVersion: v1 kind: ServiceAccount metadata: name: build-bot secrets: - name: container-registry-secrets &lt;em&gt; - name: deploy-key &lt;/em&gt;&lt;strong&gt;&amp;#60;- We need to remove this line&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;We can now create the OpenShift project that will hold all these prepared resources:&lt;/p&gt; &lt;pre&gt;$ oc new-project quarkus-greetings Now using project "quarkus-greetings" on server "https://minishift.inmyopenshift.cloud:8443".&lt;/pre&gt; &lt;p&gt;Before going forward, let&amp;#8217;s set special permissions for the just-created namespace, as suggested by the &lt;a href="https://github.com/openshift-cloud-functions/minishift-addons"&gt;Knative Minishift Addons GitHub repo&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;$ oc adm policy add-scc-to-user anyuid -z default -n quarkus-greetings $ oc adm policy add-scc-to-user privileged -z default -n quarkus-greetings&lt;/pre&gt; &lt;p&gt;And finally, we can deploy our Kubernetes resources:&lt;/p&gt; &lt;pre&gt;$ oc apply --recursive --filename target/knative/ serviceaccount/build-bot created secret/container-registry-secrets created persistentvolumeclaim/kaniko-cache created persistentvolumeclaim/m2-cache created service.serving.knative.dev/quarkus-quickstart-knative created&lt;/pre&gt; &lt;p&gt;After that, Knative Build Controller will notice the new resource, &lt;code&gt;quarkus-quickstart-knative&lt;/code&gt;, and will start the build:&lt;/p&gt; &lt;pre&gt;$ oc get pods NAME READY STATUS RESTARTS AGE quarkus-quickstart-knative-00000-lrb2b 0/1 Init:0/3 0 4s&lt;/pre&gt; &lt;p&gt;This pod is composed of three init-containers that will initialize the credentials, clone the Git repo, build it, and finally push the image to the remote registry:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;build-step-credential-initializer&lt;/li&gt; &lt;li&gt;build-step-git-source&lt;/li&gt; &lt;li&gt;build-step-docker-push&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We can also take a look to the &lt;a href="https://github.com/quarkusio/quarkus-quickstarts/blob/master/getting-started-knative/Dockerfile"&gt;Dockerfile&lt;/a&gt; that Kaniko will use for building our image in the &amp;#8220;build-step-docker-push&amp;#8221; container.&lt;/p&gt; &lt;p&gt;The Dockerfile is a multi-stage one, containing three &amp;#8220;FROM&amp;#8221; instructions, so three containers will be used. This means Kaniko will run in sequence the first two containers for building the Quarkus app&amp;#8217;s binary and then it will copy to the latest container (the third) the binary build.&lt;/p&gt; &lt;p&gt;We can finally follow the status of the build with these simple commands:&lt;/p&gt; &lt;pre&gt;$ oc get pods NAME READY STATUS RESTARTS AGE quarkus-quickstart-knative-00000-t8228 0/1 Running 0 1m $ oc logs -f -c build-step-docker-push quarkus-quickstart-knative-00000-t8228 ... INFO[0695] EXPOSE 8080 INFO[0695] cmd: EXPOSE INFO[0695] Adding exposed port: 8080/tcp INFO[0695] WORKDIR /work/ INFO[0695] cmd: workdir INFO[0695] Changed working directory to /work INFO[0695] Taking snapshot of full filesystem... INFO[0695] Skipping paths under /kaniko, as it is a whitelisted directory INFO[0695] Skipping paths under /workspace, as it is a whitelisted directory INFO[0695] Skipping paths under /cache, as it is a whitelisted directory INFO[0695] Skipping paths under /builder/home, as it is a whitelisted directory INFO[0695] Skipping paths under /run/secrets, as it is a whitelisted directory INFO[0695] Skipping paths under /var/run, as it is a whitelisted directory INFO[0695] Skipping paths under /dev, as it is a whitelisted directory INFO[0695] Skipping paths under /sys, as it is a whitelisted directory INFO[0695] Skipping paths under /proc, as it is a whitelisted directory INFO[0696] No files were changed, appending empty layer to config. No layer added to image. INFO[0696] ENTRYPOINT ["./application","-Dquarkus.http.host=0.0.0.0"] 2019/03/29 19:16:06 pushed blob sha256:72f1a1307b6f2f9dd158e31e62f06529b09652fffb2630a51c0f3e8fcdcb62ba 2019/03/29 19:16:06 pushed blob sha256:4b3c899486387dd62fe5c4a31eeb37a073dbd9e0ee0065d47bed98ffd8e0889b 2019/03/29 19:16:15 pushed blob sha256:040efd5dc88c66de8192eb1a9f9f764e49d5466381b04b1aaf528caeea156e40 2019/03/29 19:16:16 pushed blob sha256:f0034e1b296e24109590a6436bdfd4ad44500a3b8c76eb21f300861e22c40540 2019/03/29 19:16:18 pushed blob sha256:21d95e340ee05b20c5082eab8847957df806532886d34608fcf6f49e69a21360 2019/03/29 19:16:18 index.docker.io/alezzandro/quarkus-greetings:latest: digest: sha256:fe0ef7d5b8f4d7ac334a9d94d4c8a8ac9f51b884def36e6660d4c46d09ac743c size: 917&lt;/pre&gt; &lt;p&gt;Once the build process is complete, we have all the tools in place for getting our serverless service up and running (if requested). I wrote &amp;#8220;if requested&amp;#8221; because we just built a serverless application that will be spawn up ONLY if a request comes to our service.&lt;/p&gt; &lt;p&gt;We can now take a look at the created Knative resources:&lt;/p&gt; &lt;pre&gt;$ oc get ksvc NAME DOMAIN LATESTCREATED LATESTREADY READY REASON quarkus-quickstart-knative quarkus-quickstart-knative.quarkus-greetings.example.com quarkus-quickstart-knative-00000 quarkus-quickstart-knative-00000 False RevisionFailed $ oc get configuration NAME LATESTCREATED LATESTREADY READY REASON quarkus-quickstart-knative quarkus-quickstart-knative-00000 quarkus-quickstart-knative-00000 False RevisionFailed $ oc get revision NAME SERVICE NAME READY REASON quarkus-quickstart-knative-00000 quarkus-quickstart-knative-00000-service False NoTraffic $ oc get route.serving.knative.dev NAME DOMAIN READY REASON quarkus-quickstart-knative quarkus-quickstart-knative.quarkus-greetings.example.com True&lt;/pre&gt; &lt;p&gt;Don&amp;#8217;t worry about the various &amp;#8220;False&amp;#8221; and &amp;#8220;RevisionFailed&amp;#8221; status messages. They&amp;#8217;re just reporting that &amp;#8220;NoTraffic&amp;#8221; is coming to our service, so the controller and autoscaler placed our application in idle.&lt;/p&gt; &lt;p&gt;Moving forward, we&amp;#8217;re ready to launch the first request to our service. We&amp;#8217;ll use the &lt;code&gt;curl&lt;/code&gt; binary for making the HTTP request, and we need to contact the Knative Ingress Gateway that we&amp;#8217;ll find in the &lt;code&gt;istio-system&lt;/code&gt; namespace:&lt;/p&gt; &lt;pre&gt;$ oc get pods -n istio-system | grep gateway istio-egressgateway-7b46794587-c9mm8 1/1 Running 1 5h istio-ingressgateway-57f76dc4db-7khgt 1/1 Running 1 5h &lt;strong&gt;knative-ingressgateway-56d46fcb88-kmc4g 1/1 Running 1 2h&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;Keep in mind that Knative uses the HTTP &amp;#8220;Host&amp;#8221; header to route requests to its services. For this reason, we&amp;#8217;ll use some tricks to get the correct IP address and port to contact, and then we&amp;#8217;ll pass the correct hostname contained in the resource &lt;code&gt;route.serving.knative.dev&lt;/code&gt; that we discovered before:&lt;/p&gt; &lt;pre&gt;$ INGRESSGATEWAY=knative-ingressgateway $ IP_ADDRESS="$(minishift ip):$(oc get svc $INGRESSGATEWAY --namespace istio-system --output 'jsonpath={.spec.ports[?(@.port==80)].nodePort}')" $ curl -H 'Host: quarkus-quickstart-knative.quarkus-greetings.example.com' $IP_ADDRESS/greeting/alex hello alex&lt;/pre&gt; &lt;p&gt;Our service just replied to us! Let&amp;#8217;s see what that means in terms of Kubernetes resources:&lt;/p&gt; &lt;pre&gt;$ oc get pods NAME READY STATUS RESTARTS AGE quarkus-quickstart-knative-00000-874sq 0/1 Completed 0 1h &lt;strong&gt;quarkus-quickstart-knative-00000-deployment-688fcd9f4f-wccsf 2/2 Running 0 1m&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;As you can see our previously built pod is up and running and serving requests.  Let&amp;#8217;s take a closer look:&lt;/p&gt; &lt;pre&gt;$ oc describe pod quarkus-quickstart-knative-00000-deployment-688fcd9f4f-wccsf Name: quarkus-quickstart-knative-00000-deployment-688fcd9f4f-wccsf Namespace: quarkus-greetings ... Status: Running ... Containers: &lt;strong&gt;user-container:&lt;/strong&gt; ... Image: index.docker.io/alezzandro/quarkus-greetings@sha256:fe0d37b98347a321769880030951cfd1a767a0cf1f105f4665ab3a70050a6d2c ... &lt;strong&gt;queue-proxy:&lt;/strong&gt; Image: gcr.io/knative-releases/github.com/knative/serving/cmd/queue@sha256:ce66dd18f0d504e40e050f31b9de4315f8c225f308e9885eb4cbd82b2ba03c1a ...&lt;/pre&gt; &lt;p&gt;Even if I filtered the output, running the previous command, you&amp;#8217;ll see that the running pod is composed of a user-container (the quarkus-greetings service) and queue-proxy (the sidecar container that will bridge our container to the Knative system).&lt;/p&gt; &lt;h2&gt;Troubleshooting Knative in Minishift&lt;/h2&gt; &lt;p&gt;I have tried this example many times on my Minishift appliance and, like any software, it can fail. If something doesn&amp;#8217;t work properly in the &lt;em&gt;Serving&lt;/em&gt; part of this demo, the best way to start troubleshooting is to search in the &amp;#8220;knative-serving&amp;#8221; namespace:&lt;/p&gt; &lt;pre&gt;$ oc get pods -n knative-serving NAME READY STATUS RESTARTS AGE activator-6677bbc9d6-2ql94 1/1 Running 0 51m activator-6677bbc9d6-p6l7z 1/1 Running 0 51m activator-6677bbc9d6-s84zk 1/1 Running 0 51m autoscaler-5d87cc6b75-bjntw 1/1 Running 0 58m controller-f4c59f474-z5x4n 1/1 Running 1 2h webhook-5d9cbd46f7-q5rc6 1/1 Running 1 2h&lt;/pre&gt; &lt;p&gt;Take a look at the logs of activator(s), autoscaler, and controller pods. If you see errors or failures in the logs, try to restart them with a simple command like this:&lt;/p&gt; &lt;pre&gt;$ oc delete pod POD_NAME &lt;/pre&gt; &lt;p&gt;Don&amp;#8217;t worry about the consequences. Kubernetes &lt;em&gt;Deployments&lt;/em&gt; resources will spawn a brand new pod once you manually delete one.&lt;/p&gt; &lt;p&gt;That&amp;#8217;s all, folks. I hope you&amp;#8217;ll try this demo for yourself, and may the &lt;em&gt;kube&lt;/em&gt; be with you!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Ffrom-zero-to-quarkus-and-knative-the-easy-way%2F&amp;#38;linkname=From%20zero%20to%20Quarkus%20and%20Knative%3A%20The%20easy%20way" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Ffrom-zero-to-quarkus-and-knative-the-easy-way%2F&amp;#38;linkname=From%20zero%20to%20Quarkus%20and%20Knative%3A%20The%20easy%20way" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Ffrom-zero-to-quarkus-and-knative-the-easy-way%2F&amp;#38;linkname=From%20zero%20to%20Quarkus%20and%20Knative%3A%20The%20easy%20way" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Ffrom-zero-to-quarkus-and-knative-the-easy-way%2F&amp;#38;linkname=From%20zero%20to%20Quarkus%20and%20Knative%3A%20The%20easy%20way" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Ffrom-zero-to-quarkus-and-knative-the-easy-way%2F&amp;#38;linkname=From%20zero%20to%20Quarkus%20and%20Knative%3A%20The%20easy%20way" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Ffrom-zero-to-quarkus-and-knative-the-easy-way%2F&amp;#38;linkname=From%20zero%20to%20Quarkus%20and%20Knative%3A%20The%20easy%20way" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Ffrom-zero-to-quarkus-and-knative-the-easy-way%2F&amp;#38;linkname=From%20zero%20to%20Quarkus%20and%20Knative%3A%20The%20easy%20way" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Ffrom-zero-to-quarkus-and-knative-the-easy-way%2F&amp;#38;linkname=From%20zero%20to%20Quarkus%20and%20Knative%3A%20The%20easy%20way" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Ffrom-zero-to-quarkus-and-knative-the-easy-way%2F&amp;#038;title=From%20zero%20to%20Quarkus%20and%20Knative%3A%20The%20easy%20way" data-a2a-url="https://developers.redhat.com/blog/2019/04/09/from-zero-to-quarkus-and-knative-the-easy-way/" data-a2a-title="From zero to Quarkus and Knative: The easy way"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/09/from-zero-to-quarkus-and-knative-the-easy-way/"&gt;From zero to Quarkus and Knative: The easy way&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1fedqc_MGws" height="1" width="1" alt=""/&gt;</content><summary>You’ve probably already read about Quarkus, but you may not know that the superfast startup speed of Quarkus makes it the best candidate for working with Knative and serverless for your Function-as-a-Service (FaaS) projects. Quarkus, also known as Supersonic, Subatomic Java, is a Kubernetes native Java stack tailored for GraalVM and OpenJDK HotSpot, crafted from the best-of-breed Java libraries an...</summary><dc:creator>Alessandro Arrichiello</dc:creator><dc:date>2019-04-09T07:03:44Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/09/from-zero-to-quarkus-and-knative-the-easy-way/</feedburner:origLink></entry><entry><title>How to install Red Hat OpenShift 3.11 on OpenStack 13</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/a6yYpfBp9II/" /><category term="cloud" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="OpenStack" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><author><name>mohammad ahmad</name></author><id>searchisko:content:id:jbossorg_blog-how_to_install_red_hat_openshift_3_11_on_openstack_13</id><updated>2019-04-09T07:01:36Z</updated><published>2019-04-09T07:01:36Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; is a platform-as-a-service (PaaS). It orchestrates and manages containerized applications through &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;. Although OpenShift Container Platform supports cloud-native applications, it also supports custom-built applications. OpenShift Container Platform can run on a hybrid cloud configuration providing the flexibility to expand and grow.&lt;/p&gt; &lt;p&gt;&lt;a href="https://access.redhat.com/products/red-hat-openstack-platform"&gt;Red Hat OpenStack Platform&lt;/a&gt; is an infrastructure-as-a-service (IaaS). This means it is a cloud-based platform that provides virtual servers and other resources. Users either manage it through a web-based dashboard, through command-line tools, or through RESTful web services.&lt;/p&gt; &lt;p&gt;If you are considering Red Hat OpenShift Container Platform on OpenStack Platform, there are several advantages, including easily increasing the number of compute nodes and using dynamic storage.&lt;/p&gt; &lt;p&gt;In this article, I will outline the main points required to successfully install Red Hat OpenShift Container Platform on OpenStack Platform. Because my OpenStack knowledge is limited, I reached out to my colleagues for help and will not address too many OpenStack technical details here.&lt;/p&gt; &lt;p&gt;&lt;span id="more-576827"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;Before beginning your installation, you will need an OpenStack Platform environment provisioned with certain requirements. These are mainly authentication and Red Hat subscription requirements. The following sections address these.&lt;/p&gt; &lt;h3&gt;OpenStack Environment&lt;/h3&gt; &lt;p&gt;Basically, you need an environment set up as per the link below:&lt;/p&gt; &lt;pre&gt;https://docs.openshift.com/container-platform/3.11/install_config/configuring_openstack.html&lt;/pre&gt; &lt;p&gt;Therefore, before proceeding, ensure you have the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Access to a deployment instance with all the required repositories enabled, and the correct ssh keys to access your nodes&lt;/li&gt; &lt;li&gt;Valid keystone authentication credentials&lt;/li&gt; &lt;li&gt;Enough computing resources to create the cluster you need, as well as any potential growth requirements&lt;/li&gt; &lt;li&gt;DNS services that automatically add new hosts that are provisioned (Personally, I had some challenges here)&lt;/li&gt; &lt;/ol&gt; &lt;h3&gt;OpenStack keystone authentication requirements&lt;/h3&gt; &lt;p&gt;There are specific requirements for keystone authentication. This is to allow the OpenStack Platform cloud provider can authenticate with OpenStack Platform (primarily for Cinder storage).&lt;/p&gt; &lt;p&gt;The main requirement is that your OpenStack Platform user and project exist in the same domain. If you do not have them in the same domain, the installation will fail (as of OpenShift Container Platform 3.11.69).&lt;/p&gt; &lt;p&gt;Therefore, before attempting installation, ensure you can authenticate with the project ID and user via the following command:&lt;/p&gt; &lt;pre&gt;$ openstack \ --os-identity-api-version "3" \ --os-auth-url "https://openstack-default.mydomain:13000/v3" \ --os-username "myorgusername" \ --os-password "mypassword" \ --os-project-id "myprojectid" \ --os-domain-name "myorg" \ server list&lt;/pre&gt; &lt;p&gt;If the above command fails (even if you don&amp;#8217;t have any servers installed), then your OpenShift Container Platform installation will fail. This is due to the OpenShift Container Platform cloud provider being unable to authenticate for projects in a different domain to the user.&lt;/p&gt; &lt;p&gt;When you are running this command, please ensure you have NOT sourced the rc file (which contains all of the above details), because you will get false results.&lt;/p&gt; &lt;h3&gt;Populate your Red Hat OpenShift inventory with your values&lt;/h3&gt; &lt;p&gt;Here are some inventory values that will be required:&lt;/p&gt; &lt;pre&gt;$ cat inventory/group_vars/all.yml |grep rhsub rhsub_server: 'satellite.mydomain' rhsub_ak: 'openshift' rhsub_orgid: 'MyOrg' rhsub_pool: '123456789012345678901234567890'&lt;/pre&gt; &lt;h2&gt;Provision your base stack&lt;/h2&gt; &lt;p&gt;If you have all the required OpenStack settings, running the following playbook will create all the nodes required (as you have specified their numbers in your &lt;code&gt;all.yml&lt;/code&gt; file):&lt;/p&gt; &lt;pre&gt;$ source openrc.sh $ ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/openstack/openshift-cluster/provision.yml&lt;/pre&gt; &lt;p&gt;This will create your OpenShift nodes (as per your &lt;code&gt;all.yml&lt;/code&gt; file). In this example, the following settings here used:&lt;/p&gt; &lt;pre&gt;openshift_openstack_num_masters: 3 openshift_openstack_num_infra: 3 openshift_openstack_num_cns: 0 openshift_openstack_num_nodes: 3 openshift_openstack_num_etcd: 0&lt;/pre&gt; &lt;h3&gt;Check your base stack&lt;/h3&gt; &lt;p&gt;After the previous playbook is complete, check whether your dynamic inventory has been updated:&lt;/p&gt; &lt;pre&gt;$ soruce openrc.sh $ /usr/share/ansible/openshift-ansible/playbooks/openstack/inventory.py –list&lt;/pre&gt; &lt;p&gt;Your dynamic inventory must be set in your &lt;code&gt;ansible.cfg&lt;/code&gt; file. You should also make sure all nodes are contactable and have correct DNS settings.&lt;/p&gt; &lt;p&gt;Most of the problems I encountered during the installations were due to DNS. Please make sure the hostname for all your OpenShift nodes is the &lt;code&gt;fqdn&lt;/code&gt; hostname. All nodes must be able to resolve via DNS.&lt;/p&gt; &lt;h3&gt;Start your installation&lt;/h3&gt; &lt;p&gt;To begin your installation, run the following commands (I have personally increased the timeout for my Ansible playbooks):&lt;/p&gt; &lt;pre&gt;$ ansible-playbook --timeout=120 /usr/share/ansible/openshift-ansible/playbooks/openstack/openshift-cluster/prerequisites.yml $ ansible-playbook --timeout=120 /usr/share/ansible/openshift-ansible/playbooks/openstack/openshift-cluster/install.yml&lt;/pre&gt; &lt;h2&gt;Scaling up compute nodes&lt;/h2&gt; &lt;p&gt;If you are scaling up OpenShift Container Platform compute nodes on a different platform, then you may follow the standard recommended procedure to add a new node to your OpenShift Container Platform cluster.&lt;/p&gt; &lt;p&gt;However, when you are running on OpenStack Platform, you need to get these new nodes into the dynamic inventory first, before you can actually perform a joining of a node. Performing this latter task on OpenStack Platform is not an obvious task.&lt;/p&gt; &lt;p&gt;The only place I have been able to find documentation for this is in the following file (on the deployment instance/jump host):&lt;/p&gt; &lt;pre&gt;/usr/share/ansible/openshift-ansible/playbooks/openstack/configuration.md&lt;/pre&gt; &lt;p&gt;Here I provide an excerpt contained within the file above. This excerpt refers to the exact instructions required to perform a node scale-up on OpenStack Platform:&lt;/p&gt; &lt;pre&gt;Section: ### 2. Scale the Cluster ==&amp;#62; ``` $ ansible-playbook --user openshift \ -i openshift-ansible/playbooks/openstack/scaleup_inventory.py \ -i inventory \ openshift-ansible/playbooks/openstack/openshift-cluster/node-scaleup.yml ``` This will create the new OpenStack nodes, optionally create the DNS records and subscribe them to RHN, configure the `new_masters`, `new_nodes` and `new_etcd` groups and run the OpenShift scaleup tasks. When the playbook finishes, you should have new nodes up and running. Run `oc get nodes` to verify. &lt;/pre&gt; &lt;p&gt;In my case, I was interested in scaling up from three compute nodes to five compute nodes. To do that, the node count in the &lt;code&gt;all.yml&lt;/code&gt; file must be updated.&lt;/p&gt; &lt;p&gt;Step 1: Update the &lt;code&gt;all.yml&lt;/code&gt; file (example shown here):&lt;/p&gt; &lt;pre&gt;$ cat inventory/group_vars/all.yml | grep openshift_openstack_num_nodes openshift_openstack_num_nodes: 3&lt;/pre&gt; &lt;p&gt;to:&lt;/p&gt; &lt;pre&gt;$ cat inventory/group_vars/all.yml | grep openshift_openstack_num_nodes openshift_openstack_num_nodes: 5&lt;/pre&gt; &lt;p&gt;Step 2: Run the OSP specific &lt;code&gt;node-scaleup.yml&lt;/code&gt; playbook:&lt;/p&gt; &lt;pre&gt;$ ansible-playbook \ -i /home/cloud-user/inventory \ -i /usr/share/ansible/openshift-ansible/playbooks/openstack/scaleup_inventory.py \ /usr/share/ansible/openshift-ansible/playbooks/openstack/openshift-cluster/node-scaleup.yml&lt;/pre&gt; &lt;p&gt;Infra-node scaleup requires additional adjustments, which are available in &lt;code&gt;/usr/share/ansible/openshift-ansible/playbooks/openstack/configuration.md&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;I have not attempted to scale up master nodes and have not tested this.&lt;/p&gt; &lt;h2&gt;Dynamic storage&lt;/h2&gt; &lt;p&gt;OpenStack Platform Cinder storage is available to an OpenShift Container Platform cluster configured to utilize OpenStack Platform features.&lt;/p&gt; &lt;p&gt;However, you should understand that Cinder storage is a read-write-once type of storage, which means multiple pods cannot share the same storage. This aspect must be considered when designing your Red Hat OpenShift Container Platform cluster and the applications that run on them.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Installing Red Hat OpenShift Container Platform on OpenStack Platform provides many features and benefits. One main benefit is being able to scale up nodes with relative ease, and another is the ability to use OpenStack Platform Cinder storage.&lt;/p&gt; &lt;p&gt;Although good documentation is available on how to install a base cluster, the documentation on scaling up was more difficult to find. My aim in this article was to highlight all the information required to successfully install and scale up a Red Hat OpenShift cluster.&lt;/p&gt; &lt;p&gt;I didn&amp;#8217;t address OpenStack Platform technical details here primarily because of my own lack of expertise, but I did find that setting up Red Hat OpenShift Container Platform on OpenStack Platform is relatively straightforward once you have all the right information and have all the infrastructure services up and running (mainly DNS).&lt;/p&gt; &lt;p&gt;I thank my colleagues for their selfless help in completing this procedure.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Fhow-to-install-red-hat-openshift-3-11-on-openstack-13%2F&amp;#38;linkname=How%20to%20install%20Red%20Hat%20OpenShift%203.11%20on%20OpenStack%2013" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Fhow-to-install-red-hat-openshift-3-11-on-openstack-13%2F&amp;#38;linkname=How%20to%20install%20Red%20Hat%20OpenShift%203.11%20on%20OpenStack%2013" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Fhow-to-install-red-hat-openshift-3-11-on-openstack-13%2F&amp;#38;linkname=How%20to%20install%20Red%20Hat%20OpenShift%203.11%20on%20OpenStack%2013" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Fhow-to-install-red-hat-openshift-3-11-on-openstack-13%2F&amp;#38;linkname=How%20to%20install%20Red%20Hat%20OpenShift%203.11%20on%20OpenStack%2013" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Fhow-to-install-red-hat-openshift-3-11-on-openstack-13%2F&amp;#38;linkname=How%20to%20install%20Red%20Hat%20OpenShift%203.11%20on%20OpenStack%2013" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Fhow-to-install-red-hat-openshift-3-11-on-openstack-13%2F&amp;#38;linkname=How%20to%20install%20Red%20Hat%20OpenShift%203.11%20on%20OpenStack%2013" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Fhow-to-install-red-hat-openshift-3-11-on-openstack-13%2F&amp;#38;linkname=How%20to%20install%20Red%20Hat%20OpenShift%203.11%20on%20OpenStack%2013" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Fhow-to-install-red-hat-openshift-3-11-on-openstack-13%2F&amp;#38;linkname=How%20to%20install%20Red%20Hat%20OpenShift%203.11%20on%20OpenStack%2013" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F09%2Fhow-to-install-red-hat-openshift-3-11-on-openstack-13%2F&amp;#038;title=How%20to%20install%20Red%20Hat%20OpenShift%203.11%20on%20OpenStack%2013" data-a2a-url="https://developers.redhat.com/blog/2019/04/09/how-to-install-red-hat-openshift-3-11-on-openstack-13/" data-a2a-title="How to install Red Hat OpenShift 3.11 on OpenStack 13"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/09/how-to-install-red-hat-openshift-3-11-on-openstack-13/"&gt;How to install Red Hat OpenShift 3.11 on OpenStack 13&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/a6yYpfBp9II" height="1" width="1" alt=""/&gt;</content><summary>Red Hat OpenShift Container Platform is a platform-as-a-service (PaaS). It orchestrates and manages containerized applications through Kubernetes. Although OpenShift Container Platform supports cloud-native applications, it also supports custom-built applications. OpenShift Container Platform can run on a hybrid cloud configuration providing the flexibility to expand and grow. Red Hat OpenStack Pl...</summary><dc:creator>mohammad ahmad</dc:creator><dc:date>2019-04-09T07:01:36Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/09/how-to-install-red-hat-openshift-3-11-on-openstack-13/</feedburner:origLink></entry><entry><title>DevConf.US 2019 - Open Source Career with Automation Integration</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Po8sCe4PeII/devconfus-2019-open-source-career-with-automation-integration.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="jBPM" scheme="searchisko:content:tags" /><category term="workshops" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-devconf_us_2019_open_source_career_with_automation_integration</id><updated>2019-04-09T05:00:08Z</updated><published>2019-04-09T05:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://devconf.info/us/" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" target="_blank"&gt;&lt;img border="0" data-original-height="542" data-original-width="1186" height="146" src="https://2.bp.blogspot.com/-T6LZWIuPP5o/XHexg0Gq2XI/AAAAAAAAteo/pbLc5j5pqoQiZvEAZ_YdvW9M9DN3oMqeACLcBGAs/s320/Screenshot%2B2019-02-28%2Bat%2B11.01.22.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;Last year &lt;a href="http://www.schabell.org/2018/04/devconus-2018-process-driven-developement-cloud-containers.html" target="_blank"&gt;I submitted to this great conference&lt;/a&gt;, but for the first time since I've been doing conference submissions, I had to pull out due to unforeseen&amp;nbsp; circumstances.&lt;br /&gt;&lt;br /&gt;I really wanted to make a point of returning to support this event, so I have put in three of my best talks. I hope the committee gives this another chance, as I've cleared my schedule for this event and can't wait to meet everyone at Boston University on 15-17 August.&lt;br /&gt;&lt;br /&gt;Here's my list of submissions, fingers crossed:&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;These talks I've submitted are some of the best with regards to attendee reactions, participation in discussion during the sessions, and in providing content to expand attendees developer skill set.&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;How to Jump Start Your Career in Open Source&lt;/h3&gt;&lt;i&gt;It's not coincidence. It's not luck. It's not going to happen by itself, so what's the secret sauce? Understanding what makes a career in open source grow, what choices are crucial, and what actions accelerate or damage your open source future are sometimes hard to grasp. Learning to position, expand and grow your personal brand in the open source world is what this session provides. Be ready for your next step in open source. Join me for an hour of power where you'll be given a clear and easy to use plan for jump starting your open source career immediately.&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;3 Pitfalls Everyone Ignores with Microservices&lt;/h3&gt;&lt;i&gt;The daily hype is all around you. Microservices are a necessary step along the path to integration for a digitally successful future for your organization. The choices you’ve got to make don’t preclude the daily work of developing amazing applications. From containers, cloud, multicloud, and beyond, microservices are the core infrastructure ensuring your organization's flexibility in the digital world. Join us for an hour of power, where real life developer experiences are used to highlight the three top lessons we're all learning as we transition our integration infrastructure into modern day microservices.&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;7 Steps to Expanding Your AppDev Toolbox&lt;/h3&gt;&lt;i&gt;Are you ready to add automation to your development toolbox? Are you looking to integrate processes in your application development projects but not sure&amp;nbsp; where to start? Do the process integration tools intimidate you a little? No worries, we've got the easiest way to spin up your knowledge around process integration using open source technologies. Take a tour with us and learn how in 7 easy steps you can soar to new heights by adding these new skills to your AppDev toolbox. You'll walk away from this session with the learning path to integrating automation in to your next project. This session content provides all materials free, online, and available in easy to follow hands-on format. Attendees can head homeward after this session and continue advancing their skills at their own pace.&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;Hope to see you soon in Boston!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=1vMLyOIzPBY:Z53h8NFXr1E:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=1vMLyOIzPBY:Z53h8NFXr1E:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=1vMLyOIzPBY:Z53h8NFXr1E:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=1vMLyOIzPBY:Z53h8NFXr1E:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=1vMLyOIzPBY:Z53h8NFXr1E:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=1vMLyOIzPBY:Z53h8NFXr1E:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=1vMLyOIzPBY:Z53h8NFXr1E:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=1vMLyOIzPBY:Z53h8NFXr1E:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=1vMLyOIzPBY:Z53h8NFXr1E:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=1vMLyOIzPBY:Z53h8NFXr1E:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=1vMLyOIzPBY:Z53h8NFXr1E:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/1vMLyOIzPBY" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Po8sCe4PeII" height="1" width="1" alt=""/&gt;</content><summary>Last year I submitted to this great conference, but for the first time since I've been doing conference submissions, I had to pull out due to unforeseen  circumstances. I really wanted to make a point of returning to support this event, so I have put in three of my best talks. I hope the committee gives this another chance, as I've cleared my schedule for this event and can't wait to meet everyone...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-04-09T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/1vMLyOIzPBY/devconfus-2019-open-source-career-with-automation-integration.html</feedburner:origLink></entry><entry><title>Operator 0.2.1 out with DNS ping and expanded customizations</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/zWWkQ73X2Jo/operator-021-out-with-dns-ping-and.html" /><category term="beta release" scheme="searchisko:content:tags" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="operator" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><author><name>Galder Zamarreño</name></author><id>searchisko:content:id:jbossorg_blog-operator_0_2_1_out_with_dns_ping_and_expanded_customizations</id><updated>2019-04-08T08:00:05Z</updated><published>2019-04-08T08:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;We've just completed the release of the Infinispan Operator version 0.2.1. In this second minor release, we've added the following features:&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;DNS Cluster Discovery&lt;/h3&gt;&lt;br /&gt;Cluster nodes now discover each other using DNS ping,&amp;nbsp;which uses name lookups. Each node publishes a headless service which they use to locate each other. Previously, Kubernetes APIs were queried to discover other nodes, but this required administrator rights. DNS ping does not require admin permissions.&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Configurable Image&lt;/h3&gt;&lt;br /&gt;The Infinispan server image used by the operator is now configurable, e.g.&lt;br /&gt;&lt;br /&gt;&lt;script src="https://gist.github.com/galderz/2d3f06dfb3c5fa0d17fa1e7059ad9531.js"&gt;&lt;/script&gt; &lt;h3 style="text-align: left;"&gt;&lt;br /&gt;&lt;/h3&gt;&lt;h3 style="text-align: left;"&gt;Configurable XML&lt;/h3&gt;&lt;br /&gt;You can now provide their own custom Infinispan server XML referencing an existing ConfigMap:&lt;br /&gt;&lt;br /&gt;&lt;script src="https://gist.github.com/galderz/32cf3b56d3914eef1c06044d3d76f638.js"&gt;&lt;/script&gt; Note that this example requires a ConfigMap with the XML file to be created before hand.&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Next Steps&lt;/h3&gt;&lt;br /&gt;We're already working on version 0.3.0, and in parallel we've been working on our first OperatorHub submission. We hope to have some news for you very soon :)&lt;br /&gt;&lt;br /&gt;Cheers,&lt;br /&gt;Galder&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/Infinispan/~4/8jeDuSHvJDo" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/zWWkQ73X2Jo" height="1" width="1" alt=""/&gt;</content><summary>We've just completed the release of the Infinispan Operator version 0.2.1. In this second minor release, we've added the following features: DNS Cluster Discovery Cluster nodes now discover each other using DNS ping, which uses name lookups. Each node publishes a headless service which they use to locate each other. Previously, Kubernetes APIs were queried to discover other nodes, but this require...</summary><dc:creator>Galder Zamarreño</dc:creator><dc:date>2019-04-08T08:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/Infinispan/~3/8jeDuSHvJDo/operator-021-out-with-dns-ping-and.html</feedburner:origLink></entry><entry><title>Reduce application image build times with .NET Core incremental builds</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/joDTf-CNcuE/" /><category term=".net" scheme="searchisko:content:tags" /><category term=".NET Core" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><author><name>Tom Deseyn</name></author><id>searchisko:content:id:jbossorg_blog-reduce_application_image_build_times_with_net_core_incremental_builds</id><updated>2019-04-08T07:03:09Z</updated><published>2019-04-08T07:03:09Z</published><content type="html">&lt;p&gt;In a &lt;a href="https://developers.redhat.com/blog/2018/12/13/building-net-core-container-images-using-s2i/"&gt;previous article&lt;/a&gt;, we talked about using containers to build .NET Core application images to make our builds portable and reproducible. Because each build starts from scratch, some time is spent downloading and extracting NuGet packages.&lt;/p&gt; &lt;p&gt;One way to reduce build times is to &lt;a href="https://developers.redhat.com/blog/2019/01/08/local-nuget-server-red-hat-openshift-container-platform/"&gt;add a local NuGet server&lt;/a&gt;; this brings packages closer to the build machines, which reduces the time to download the packages. In this article, we&amp;#8217;ll look at how the new incremental build feature of the .NET Core S2I builder can further reduce build times.&lt;span id="more-581227"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The .NET Core S2I builder now supports incremental builds. When we do an incremental build, the builder will reuse the NuGet packages from a previously built application image. So, the first build of the application image will fetch packages from the NuGet server, and successive builds will reuse those packages.&lt;/p&gt; &lt;p&gt;To perform incremental builds using the &lt;a href="https://github.com/openshift/source-to-image/"&gt;source-to-image&lt;/a&gt; (&lt;code&gt;s2i&lt;/code&gt;) tool, we need to pass the &lt;code&gt;--incremental&lt;/code&gt; flag. By default, the .NET Core S2I builder will remove NuGet packages to reduce the size of the application image. To keep those packages around, we need to set the &lt;code&gt;DOTNET_INCREMENTAL&lt;/code&gt; environment variable to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;On my development machine, performing an &lt;code&gt;s2i&lt;/code&gt; build for the &lt;code&gt;dotnet new mvc&lt;/code&gt;-template gives these build times:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;S2I&lt;/th&gt; &lt;th&gt;Total time&lt;/th&gt; &lt;th&gt;Restore time&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;First build&lt;/td&gt; &lt;td&gt;35s&lt;/td&gt; &lt;td&gt;16.5s&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Successive build&lt;/td&gt; &lt;td&gt;24.5s&lt;/td&gt; &lt;td&gt;0.5s&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;We see the build time goes down thanks to the reduced restore time; however, the total time doesn&amp;#8217;t go down by the same amount. This is because we spend extra time to extract the NuGet packages from the previous application image. Note that the previous application image is already present on the build machine, so we spend no time fetching it from an image registry.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/openshift/overview/"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; can also be configured to perform incremental builds. Let’s look at the build time difference using a free &lt;a href="https://manage.openshift.com/"&gt;Red Hat OpenShift Online&lt;/a&gt; account.&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;Free OpenShift Online account&lt;/th&gt; &lt;th&gt;Total time&lt;/th&gt; &lt;th&gt;Restore time&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Non-incremental build&lt;/td&gt; &lt;td&gt;2m18s&lt;/td&gt; &lt;td&gt;28.5s&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Successive incremental build&lt;/td&gt; &lt;td&gt;4m45s&lt;/td&gt; &lt;td&gt;2s&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;In this case, the incremental build is slower. Fetching packages from the NuGet server is faster than retrieving the previously built application image from the cluster container image registry and then extracting the packages from it.&lt;/p&gt; &lt;p&gt;Let’s do this again. Now we’ll use an on-premise Red Hat OpenShift test cluster. These are the build times:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;OpenShift test cluster&lt;/th&gt; &lt;th&gt;Total time&lt;/th&gt; &lt;th&gt;Restore time&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Non-incremental build&lt;/td&gt; &lt;td&gt;1m12s&lt;/td&gt; &lt;td&gt;12.72s&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Successive incremental build&lt;/td&gt; &lt;td&gt;1m53s&lt;/td&gt; &lt;td&gt;1s&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;The build times are closer, but again, the non-incremental build is faster thanks to the high bandwidth to the NuGet server compared to the container registry.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, we looked at the new incremental build feature of the S2I .NET Core builder. When using &lt;code&gt;s2i&lt;/code&gt; on a developer machine, the incremental builds are faster when a previously built application image is already present on the machine. This is not the case when building on OpenShift. It depends on the bandwidth to the cluster image registry compared to the bandwidth to the NuGet server whether incremental or non-incremental builds are faster.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F08%2Freduce-application-image-build-times-with-net-core-incremental-builds%2F&amp;#38;linkname=Reduce%20application%20image%20build%20times%20with%20.NET%20Core%20incremental%20builds" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F08%2Freduce-application-image-build-times-with-net-core-incremental-builds%2F&amp;#38;linkname=Reduce%20application%20image%20build%20times%20with%20.NET%20Core%20incremental%20builds" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F08%2Freduce-application-image-build-times-with-net-core-incremental-builds%2F&amp;#38;linkname=Reduce%20application%20image%20build%20times%20with%20.NET%20Core%20incremental%20builds" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F08%2Freduce-application-image-build-times-with-net-core-incremental-builds%2F&amp;#38;linkname=Reduce%20application%20image%20build%20times%20with%20.NET%20Core%20incremental%20builds" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F08%2Freduce-application-image-build-times-with-net-core-incremental-builds%2F&amp;#38;linkname=Reduce%20application%20image%20build%20times%20with%20.NET%20Core%20incremental%20builds" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F08%2Freduce-application-image-build-times-with-net-core-incremental-builds%2F&amp;#38;linkname=Reduce%20application%20image%20build%20times%20with%20.NET%20Core%20incremental%20builds" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F08%2Freduce-application-image-build-times-with-net-core-incremental-builds%2F&amp;#38;linkname=Reduce%20application%20image%20build%20times%20with%20.NET%20Core%20incremental%20builds" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F08%2Freduce-application-image-build-times-with-net-core-incremental-builds%2F&amp;#38;linkname=Reduce%20application%20image%20build%20times%20with%20.NET%20Core%20incremental%20builds" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F08%2Freduce-application-image-build-times-with-net-core-incremental-builds%2F&amp;#038;title=Reduce%20application%20image%20build%20times%20with%20.NET%20Core%20incremental%20builds" data-a2a-url="https://developers.redhat.com/blog/2019/04/08/reduce-application-image-build-times-with-net-core-incremental-builds/" data-a2a-title="Reduce application image build times with .NET Core incremental builds"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/08/reduce-application-image-build-times-with-net-core-incremental-builds/"&gt;Reduce application image build times with .NET Core incremental builds&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/joDTf-CNcuE" height="1" width="1" alt=""/&gt;</content><summary>In a previous article, we talked about using containers to build .NET Core application images to make our builds portable and reproducible. Because each build starts from scratch, some time is spent downloading and extracting NuGet packages. One way to reduce build times is to add a local NuGet server; this brings packages closer to the build machines, which reduces the time to download the packag...</summary><dc:creator>Tom Deseyn</dc:creator><dc:date>2019-04-08T07:03:09Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/08/reduce-application-image-build-times-with-net-core-incremental-builds/</feedburner:origLink></entry></feed>
